model:
  dropout: 0.35 

training:
  batch_size: 32
  num_epochs: 10
  learning_rate: 0.00003
  weight_decay: 0.01

data:
  max_seq_len: 512

general:
  seed: 42  